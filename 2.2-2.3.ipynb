{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b6b12b",
   "metadata": {},
   "source": [
    "# 2.2 Predicting RNA secondary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930de0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ViennaRNA version 2.7.1 is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Try to import the library we just installed\n",
    "try:\n",
    "    import RNA\n",
    "    print(f\"‚úÖ ViennaRNA version {RNA.__version__} is ready.\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå ViennaRNA not found. (If you installed it, restart your kernel).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fc1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Folding Human (514 sequences)...\n",
      "üß¨ Folding House mouse (404 sequences)...\n",
      "üß¨ Folding Fruit fly (140 sequences)...\n",
      "üß¨ Folding Roundworm (138 sequences)...\n",
      "\n",
      "‚úÖ Success! Dataset with folding saved to: merged_data_2.2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. SETUP\n",
    "# ---------------------------------------------------------\n",
    "input_file = 'merged_data.xlsx'\n",
    "# We will save the result here\n",
    "output_file = 'merged_data_2.2.xlsx' \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. FOLDING FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def fold_sequence_only(row):\n",
    "    # Safety check for empty sequences\n",
    "    if pd.isna(row['Precursor sequence']):\n",
    "        return pd.Series({'structure': None, 'MFE': None})\n",
    "    \n",
    "    # Clean and prepare sequence (remove whitespace, uppercase, T->U)\n",
    "    seq = str(row['Precursor sequence']).strip().upper().replace('T', 'U')\n",
    "    \n",
    "    # --- Perform Folding ---\n",
    "    # RNA.fold returns (structure_string, mfe_float)\n",
    "    structure, mfe = RNA.fold(seq)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'structure': structure,\n",
    "        'MFE': mfe\n",
    "    })\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    # Read the Excel file (all sheets)\n",
    "    all_sheets = pd.read_excel(input_file, sheet_name=None)\n",
    "    processed_sheets = {}\n",
    "\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for species, df in all_sheets.items():\n",
    "            print(f\"üß¨ Folding {species} ({len(df)} sequences)...\")\n",
    "            \n",
    "            # Apply the folding function\n",
    "            # This returns a DataFrame with just 'structure' and 'MFE'\n",
    "            folding_results = df.apply(fold_sequence_only, axis=1)\n",
    "            \n",
    "            # Remove existing structure/MFE columns if re-running (to avoid duplicates)\n",
    "            df_clean = df.drop(columns=['structure', 'MFE'], errors='ignore')\n",
    "            \n",
    "            # Combine: Original Data + New Folding Columns\n",
    "            final_df = pd.concat([df_clean, folding_results], axis=1)\n",
    "            \n",
    "            # Save to the new sheet\n",
    "            final_df.to_excel(writer, sheet_name=species, index=False)\n",
    "            \n",
    "    print(f\"\\n‚úÖ Success! Dataset with folding saved to: {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {input_file}. Make sure it's in the same folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16aa891",
   "metadata": {},
   "source": [
    "# 2.3 Extracting Structural Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf649ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading merged_data_2.2.xlsx...\n",
      "Processing Human...\n",
      "Processing House mouse...\n",
      "Processing Fruit fly...\n",
      "Processing Roundworm...\n",
      "‚úÖ Done! Features saved to merged_data_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "INPUT_FILE = \"merged_data_2.2.xlsx\"\n",
    "OUTPUT_FILE = \"merged_data_final.xlsx\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def get_dot_bracket_pairs(structure):\n",
    "    \"\"\"\n",
    "    Parses a dot-bracket string (e.g. \"((..))\") into a list of pairs (i, j).\n",
    "    Returns a set of tuples {(i, j), ...} where i < j.\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    stack = []\n",
    "    for i, char in enumerate(structure):\n",
    "        if char == '(':\n",
    "            stack.append(i)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                start = stack.pop()\n",
    "                pairs.add((start, i))\n",
    "    return pairs\n",
    "\n",
    "def get_consecutive_unmatched_max(sub_structure):\n",
    "    \"\"\"\n",
    "    Returns the length of the longest run of dots '.' in a string.\n",
    "    \"\"\"\n",
    "    if not sub_structure:\n",
    "        return 0\n",
    "    # Split by any paired characters ('(' or ')') to get chunks of dots\n",
    "    # e.g. \"((...))...\" -> [\"\", \"\", \"...\", \"\", \"...\", \"\"]\n",
    "    # Then take max length\n",
    "    tokens = re.split(r'[()]', sub_structure)\n",
    "    return max(len(t) for t in tokens)\n",
    "\n",
    "def analyze_structure(row):\n",
    "    # Safety checks\n",
    "    if pd.isna(row.get('structure')) or pd.isna(row.get('Precursor sequence')):\n",
    "        return pd.Series({})\n",
    "    \n",
    "    seq = str(row['Precursor sequence']).strip().upper().replace('T', 'U')\n",
    "    struct = str(row['structure']).strip()\n",
    "    \n",
    "    # Check if lengths match (crucial for indexing)\n",
    "    if len(seq) != len(struct):\n",
    "        # Fallback: if lengths differ, we can't map pairs accurately. Return empty.\n",
    "        return pd.Series({'Feature_Extraction_Error': 'Length Mismatch'})\n",
    "\n",
    "    # 1. Identify Regions (Indices)\n",
    "    # We need to find where Mature and Star start/end in the Precursor\n",
    "    mat_seq = str(row.get('Mature sequence', '')).strip().upper().replace('T', 'U')\n",
    "    star_seq = str(row.get('Star sequence', '')).strip().upper().replace('T', 'U')\n",
    "    \n",
    "    # Find start index. Note: find() returns first occurrence.\n",
    "    mat_start = seq.find(mat_seq)\n",
    "    mat_end = mat_start + len(mat_seq) if mat_start != -1 else -1\n",
    "    \n",
    "    star_start = seq.find(star_seq) if star_seq and star_seq != 'NAN' else -1\n",
    "    star_end = star_start + len(star_seq) if star_start != -1 else -1\n",
    "\n",
    "    # 2. Parse Structure\n",
    "    pairs = get_dot_bracket_pairs(struct)\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # CALCULATE REQUIRED FEATURES \n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    # 1. MFE is already in the row\n",
    "    \n",
    "    # 2. Number of base-pairs in Mature\n",
    "    # Interpretation: How many bases IN the mature region are paired?\n",
    "    # (Checking if index k is in mature range and struct[k] is '(' or ')')\n",
    "    mat_bp_count = 0\n",
    "    if mat_start != -1:\n",
    "        mat_sub = struct[mat_start:mat_end]\n",
    "        mat_bp_count = mat_sub.count('(') + mat_sub.count(')')\n",
    "        mat_bp_count = mat_bp_count\n",
    "        \n",
    "    # 3. Number of base-pairs in Star\n",
    "    star_bp_count = 0\n",
    "    if star_start != -1:\n",
    "        star_sub = struct[star_start:star_end]\n",
    "        star_bp_count = (star_sub.count('(') + star_sub.count(')'))\n",
    "\n",
    "    # 4. Loop Size (Terminal Loop)\n",
    "    # The loop enclosed by the pair with NO other pairs inside it.\n",
    "    # If multiple (e.g. multiloop), we take the largest one.\n",
    "    terminal_loop_size = 0\n",
    "    candidates = []\n",
    "    \n",
    "    for (i, j) in pairs:\n",
    "        # Check if this pair encloses any other pair\n",
    "        is_terminal = True\n",
    "        for (k, l) in pairs:\n",
    "            if (k > i) and (l < j):\n",
    "                is_terminal = False\n",
    "                break\n",
    "        \n",
    "        if is_terminal:\n",
    "            # The size is the number of nucleotides between i and j\n",
    "            candidates.append(j - i - 1)\n",
    "            \n",
    "    if candidates:\n",
    "        terminal_loop_size = max(candidates)\n",
    "\n",
    "    # 5, 6, 7. GC / AU / GU counts across Precursor\n",
    "    gc_count = 0\n",
    "    au_count = 0\n",
    "    gu_count = 0\n",
    "    \n",
    "    for (i, j) in pairs:\n",
    "        b1 = seq[i]\n",
    "        b2 = seq[j]\n",
    "        pair_str = \"\".join(sorted([b1, b2])) # Sort to normalize (e.g. UG -> GU)\n",
    "        \n",
    "        if pair_str == 'CG':\n",
    "            gc_count += 1\n",
    "        elif pair_str == 'AU':\n",
    "            au_count += 1\n",
    "        elif pair_str == 'GU':\n",
    "            gu_count += 1\n",
    "            \n",
    "    # -----------------------------------------------------\n",
    "    # CALCULATE ADDITIONAL FEATURES\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    # A. Unmatched nts on mature side\n",
    "    mat_unmatched = 0\n",
    "    mat_max_consecutive = 0\n",
    "    if mat_start != -1:\n",
    "        mat_sub = struct[mat_start:mat_end]\n",
    "        mat_unmatched = mat_sub.count('.')\n",
    "        mat_max_consecutive = get_consecutive_unmatched_max(mat_sub)\n",
    "\n",
    "    # B. Unmatched nts on star side\n",
    "    star_unmatched = 0\n",
    "    star_max_consecutive = 0\n",
    "    if star_start != -1:\n",
    "        star_sub = struct[star_start:star_end]\n",
    "        star_unmatched = star_sub.count('.')\n",
    "        star_max_consecutive = get_consecutive_unmatched_max(star_sub)\n",
    "        \n",
    "    # C. Unmatched nts on precursor (Total)\n",
    "    pre_unmatched = struct.count('.')\n",
    "\n",
    "    return pd.Series({\n",
    "        # Required\n",
    "        'Mature_BP_Count': mat_bp_count,\n",
    "        'Star_BP_Count': star_bp_count,\n",
    "        'Terminal_Loop_Size': terminal_loop_size,\n",
    "        'GC_Pairs_Precursor': gc_count,\n",
    "        'AU_Pairs_Precursor': au_count,\n",
    "        'GU_Pairs_Precursor': gu_count,\n",
    "        \n",
    "        # Additional\n",
    "        'Mature_Unmatched_Count': mat_unmatched,\n",
    "        'Star_Unmatched_Count': star_unmatched,\n",
    "        'Precursor_Unmatched_Count': pre_unmatched,\n",
    "        'Mature_Max_Consecutive_Unmatched': mat_max_consecutive,\n",
    "        'Star_Max_Consecutive_Unmatched': star_max_consecutive\n",
    "    })\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTION LOOP\n",
    "# ---------------------------------------------------------\n",
    "def main():\n",
    "    print(f\"Reading {INPUT_FILE}...\")\n",
    "    try:\n",
    "        xls = pd.ExcelFile(INPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            print(f\"Processing {sheet_name}...\")\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            \n",
    "            # Apply analysis\n",
    "            features_df = df.apply(analyze_structure, axis=1)\n",
    "            \n",
    "            # Combine original data with new features\n",
    "            final_df = pd.concat([df, features_df], axis=1)\n",
    "            \n",
    "            # Save\n",
    "            final_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "    print(f\"‚úÖ Done! Features saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3778868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
